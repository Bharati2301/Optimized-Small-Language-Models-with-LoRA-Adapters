{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/EleutherAI/lm-evaluation-harness","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(hf_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!lm_eval --model hf \\\n    --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 \\\n    --tasks hellaswag \\\n    --device cuda:0 \\\n    --batch_size 8 \\\n    --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n    --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=meta-llama/Llama-3.2-1B-Instruct \\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=meta-llama/Llama-3.2-3B-Instruct \\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-All-r32-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-All-r64-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-All-r128-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=bharati2324/Llama-1B-Code-LoRA-r32-attn-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-Attn-r64-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-Attn-r128-merged\\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r32_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=bharati2324/Llama-1B-Summarization-LoRA-r32-mlp-merged \\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r64_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-MLP-r64-merged \\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r64_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !lm_eval --model hf \\\n#     --model_args pretrained=vijay-ravichander/Llama-1B-Summarization-LoRA-MLP-r128-merged \\\n#     --tasks hellaswag \\\n#     --device cuda:0 \\\n#     --batch_size 8 \\\n#     --output_path /kaggle/working/llama1b_r128_base_results_gsm8k \\\n#     --log_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}